{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-M3TUK91:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b50c38aa08>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create spark PySpark instance\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some important functions\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>m</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "5        6   1   1   0   0   1   1   1   1   1    1        21               8   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "5   m           black       no                  no          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  \n",
       "5               Yes  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "path = \"../Datasets/\"\n",
    "\n",
    "df = spark.read.csv(path+\"Toddler Autism dataset July 2018.csv\", inferSchema=True, header=True)\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing schema\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the dataset is balanced between the two classes of the dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|Class/ASD Traits |Class_Count|\n",
      "+-----------------+-----------+\n",
      "|               No|        326|\n",
      "|              Yes|        728|\n",
      "+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Class/ASD Traits \").agg(count(df[\"Class/ASD Traits \"]).alias(\"Class_Count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data seems to be balanced here\n",
    "# Dataset is unbalanced in case there are only 10 cases for one of the class or less than 1% of the whole \n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Data\n",
    "\n",
    "Mlib requires all input columns to be vectorized. We also need to renmae the dependent variable into label since that is what is expected for all MLlib applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the input columns\n",
    "input_columns = df.columns # Collect the column names as a list\n",
    "input_columns = input_columns[1:-1] # since we can remove Case_no and dependent variable\n",
    "\n",
    "dependent_var = 'Class/ASD Traits ' # assigning the dependent variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to reindex the dependent variable starting from zero\n",
    "\n",
    "# renaming dependent variable to String DataType\n",
    "renamed = df.withColumn('label_str', df[dependent_var].cast(StringType())) \n",
    "\n",
    "#Changing the column name to label which is expected by MLlib applications and changing the string to numeric\n",
    "# starting from zero\n",
    "indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\")\n",
    "# fit method will just calculate the label output columns and transform will apply those changes to the \n",
    "# renamed dataframe\n",
    "indexed = indexer.fit(renamed).transform(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0  ...        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0  ...        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0  ...        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1  ...        24              10   \n",
       "\n",
       "   Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0    f  middle eastern      yes                  no          family member   \n",
       "1    m  White European      yes                  no          family member   \n",
       "2    m  middle eastern      yes                  no          family member   \n",
       "3    m        Hispanic       no                  no          family member   \n",
       "\n",
       "  Class/ASD Traits  label_str label  \n",
       "0                No        No   1.0  \n",
       "1               Yes       Yes   0.0  \n",
       "2               Yes       Yes   0.0  \n",
       "3               Yes       Yes   0.0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all input data into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all input data into numeric\n",
    "\n",
    "# Creating a list of for numeric columns and string columns\n",
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "\n",
    "# looping through each column to check if that is of String type or integer type\n",
    "for column in input_columns:\n",
    "    # checking for string type\n",
    "    if str(indexed.schema[column].dataType) == \"StringType\":\n",
    "        #print(\"Column \",column,\" is of String Type\")\n",
    "        # Setting up the StringIndexer function, and chaning the name of the new column\n",
    "        indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\")\n",
    "        # calling fit and transform method to make this change in the dataframe\n",
    "        indexed = indexer.fit(indexed).transform(indexed)\n",
    "        #renaming the column to a new column so that it can be distinguishable from the original\n",
    "        new_col_name = column+\"_num\"\n",
    "        #Add the new column in the list\n",
    "        string_inputs.append(new_col_name)\n",
    "    \n",
    "    else:\n",
    "        # in case of numeric column, just add it to the list\n",
    "        #print(\"Column \",column,\" is of Integer Type\")\n",
    "        numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex_num', 'Ethnicity_num', 'Jaundice_num', 'Family_mem_with_ASD_num', 'Who completed the test_num']\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Qchat-10-Score']\n"
     ]
    }
   ],
   "source": [
    "print(string_inputs)\n",
    "print(numeric_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      " |-- label_str: string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- Sex_num: double (nullable = false)\n",
      " |-- Ethnicity_num: double (nullable = false)\n",
      " |-- Jaundice_num: double (nullable = false)\n",
      " |-- Family_mem_with_ASD_num: double (nullable = false)\n",
      " |-- Who completed the test_num: double (nullable = false)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(indexed.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating for skewness and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flooring and capping\n",
    "# Plus if right skewed, the take log+1\n",
    "# if left skewed, do exp transformation\n",
    "\n",
    "# create a empty dictionary\n",
    "d = {}\n",
    "\n",
    "# doing the top and bottom 1%\n",
    "for col in numeric_inputs:\n",
    "    # this dictionary will store the top and bottom 1% quantiles for each numeric column\n",
    "    d[col] = indexed.approxQuantile(col, [0.01, 0.99], 0.25)\n",
    "\n",
    "# now check for skewness for all numeric cols\n",
    "for col in numeric_inputs:\n",
    "    # collecting the skewness for each numeric column\n",
    "    # skew is a list \n",
    "    skew = indexed.agg(skewness(indexed[col])).collect()\n",
    "    skew = skew[0][0]\n",
    "    \n",
    "    # if skewness is found, below code will make the necessary changes\n",
    "    if skew >1: # if right skew, floor, cap and log(x+1)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        log(when(indexed[col] < d[col][0], d[col][0]) \\\n",
    "           .when(indexed[col] > d[col][1], d[col][1]) \\\n",
    "           .otherwise(indexed[col]) +1).alias(col))\n",
    "        print(col+\" has been treated for positive (right) skewness. (skew=)\", skew, \")\")\n",
    "    elif skew < -1: #if left skew, floor, cap, and exp(x)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        exp(when(indexed[col] < d[col][0], d[col][0]) \\\n",
    "           .when(indexed[col] > d[col][1], d[col][1]) \\\n",
    "           .otherwise(indexed[col])).alias(col))\n",
    "        print(col+\" has been treated for negative (left )skewness, (skew=)\", skew,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no issue of skewness in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the negative values in the dataset.\n",
    "\n",
    "We need to check only the original numeric columns since indexed column (new numeric columns) won't have any negative values in them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values were found in your dataframe\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mins for all columns in the dataset\n",
    "minimums = df.select([min(c).alias(c) for c in indexed.columns if c in numeric_inputs])\n",
    "# Create an array for all mins and select only the input cols\n",
    "min_array = minimums.select(array(numeric_inputs).alias(\"mins\"))\n",
    "# Collect the global minimum as Python object\n",
    "df_minimum = min_array.select(array_min(min_array.mins)).collect()\n",
    "# get the global minimum\n",
    "df_minimum = df_minimum[0][0]\n",
    "\n",
    "# If there is any Negative values found in the df, print a warning message\n",
    "if df_minimum < 0:\n",
    "    print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contain negative values\")\n",
    "else:\n",
    "    print(\"No negative values were found in your dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we correct any negative values that may have been found above, we need to vectorize the dataframe\n",
    "# because the function that we will be using to that correction requires a vector\n",
    "# Now create your final features list\n",
    "\n",
    "features_list = numeric_inputs + string_inputs\n",
    "# Create your vector assembler object\n",
    "assembler = VectorAssembler(inputCols=features_list, outputCol='features')\n",
    "# And Call on the vector assembler to transform the dataframe\n",
    "output = assembler.transform(indexed).select('features', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+-----+\n",
      "|features                                                                 |label|\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "|(17,[6,7,9,10,11,12,13,14],[1.0,1.0,1.0,28.0,3.0,1.0,2.0,1.0])           |1.0  |\n",
      "|(17,[0,1,5,6,10,11,14],[1.0,1.0,1.0,1.0,36.0,4.0,1.0])                   |0.0  |\n",
      "|(17,[0,6,7,9,10,11,13,14],[1.0,1.0,1.0,1.0,36.0,4.0,2.0,1.0])            |0.0  |\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,24.0,10.0,0.0,5.0,0.0,0.0,0.0]  |0.0  |\n",
      "|[1.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,20.0,9.0,1.0,0.0,0.0,1.0,0.0]   |0.0  |\n",
      "|[1.0,1.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,21.0,8.0,0.0,4.0,0.0,0.0,0.0]   |0.0  |\n",
      "|(17,[0,3,4,5,8,10,11,13,14],[1.0,1.0,1.0,1.0,1.0,33.0,5.0,1.0,1.0])      |0.0  |\n",
      "|(17,[1,4,6,7,8,9,10,11,13,14],[1.0,1.0,1.0,1.0,1.0,1.0,33.0,6.0,1.0,1.0])|0.0  |\n",
      "|(17,[6,9,10,11,13],[1.0,1.0,36.0,2.0,1.0])                               |1.0  |\n",
      "|[1.0,1.0,1.0,0.0,1.0,1.0,0.0,1.0,1.0,1.0,22.0,8.0,0.0,3.0,0.0,0.0,1.0]   |0.0  |\n",
      "|[1.0,0.0,0.0,1.0,0.0,1.0,1.0,0.0,1.0,1.0,36.0,6.0,0.0,5.0,1.0,1.0,0.0]   |0.0  |\n",
      "|[1.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,17.0,8.0,0.0,2.0,1.0,0.0,0.0]   |0.0  |\n",
      "|(17,[10,12,13,14],[25.0,1.0,2.0,1.0])                                    |1.0  |\n",
      "|[1.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,1.0,1.0,15.0,7.0,1.0,2.0,1.0,0.0,0.0]   |0.0  |\n",
      "|(17,[10,13],[18.0,2.0])                                                  |1.0  |\n",
      "|(17,[0,1,2,4,6,7,9,10,11,13],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,12.0,7.0,4.0]) |0.0  |\n",
      "|(17,[10,13,15],[36.0,2.0,1.0])                                           |1.0  |\n",
      "|[1.0,1.0,1.0,0.0,1.0,1.0,1.0,1.0,0.0,1.0,12.0,8.0,1.0,2.0,1.0,0.0,0.0]   |0.0  |\n",
      "|(17,[0,4,9,10,11,12,13],[1.0,1.0,1.0,29.0,3.0,1.0,2.0])                  |1.0  |\n",
      "|[1.0,1.0,1.0,0.0,1.0,0.0,1.0,1.0,0.0,1.0,12.0,7.0,1.0,4.0,0.0,0.0,0.0]   |0.0  |\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled to range: [0.000000, 1000.000000]\n",
      "+--------------------+-----+--------------------+\n",
      "|            features|label|      scaledFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(17,[6,7,9,10,11,...|  1.0|[0.0,0.0,0.0,0.0,...|\n",
      "|(17,[0,1,5,6,10,1...|  0.0|[1000.0,1000.0,0....|\n",
      "|(17,[0,6,7,9,10,1...|  0.0|[1000.0,0.0,0.0,0...|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|[1000.0,1000.0,10...|\n",
      "|[1.0,1.0,0.0,1.0,...|  0.0|[1000.0,1000.0,0....|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,0.0,0.0,0...|  0.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,0.0,0.0,1...|  0.0|\n",
      "|[0.0,1000.0,0.0,0...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,0.0,0.0,1...|  0.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,0.0,0.0,0...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a min,max scalar object\n",
    "# we can perform scaling on the dataframe, this will fix the negative value issue if there is any in the\n",
    "# dataframe\n",
    "# let's take the range from 0 to 1000\n",
    "scalar = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", min=0, max=1000)\n",
    "print(\"Features scaled to range: [%f, %f]\" % (scalar.getMin(), scalar.getMax()))\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scalar.fit(output)\n",
    "# transform each feature according to min, max range\n",
    "scaled_data = scalerModel.transform(output)\n",
    "#scaled_data.show(5)\n",
    "# selecting only the label and new scaled features from the scaled_data dataframe\n",
    "final_data = scaled_data.select('scaledFeatures', 'label')\n",
    "\n",
    "# Rename the scaledFeature to its default name\n",
    "final_data = final_data.withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,0.0,0.0,0...|  0.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,1000.0,0....|  0.0|\n",
      "|[1000.0,0.0,0.0,1...|  0.0|\n",
      "|[0.0,1000.0,0.0,0...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,0.0,0.0,1...|  0.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "|[1000.0,0.0,0.0,0...|  1.0|\n",
      "|[1000.0,1000.0,10...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data randomly in 70:30 ratio\n",
    "train, test = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records in training dataset:  741\n",
      "total number of records in testing dataset:  313\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of records in training dataset: \",train.count())\n",
    "print(\"total number of records in testing dataset: \", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dependencies\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our evaluation objects\n",
    "# this is used when we have binary classification problem such as ours\n",
    "Bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "# below evaluation is mainly used for multiclass classification problem but can also be used and checked\n",
    "# for binary classification problem\n",
    "MC_evaluator = MulticlassClassificationEvaluator(metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.64407953386...|[2.00474222782246...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.77377908621...|[1.76088396439985...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.33564583937...|[2.72903804410540...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.33564583937...|[2.72903804410540...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.32819268224...|[2.74945398054480...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-123.43548930532...|[2.46972230293454...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.26320731887...|[7.97560655480689...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.83847243109...|[4.48672299726888...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.71777744895...|[1.37607119638720...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.96749997207...|[3.94360409300971...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.91111834192...|[4.17233854072615...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.60747927328...|[5.65260074669627...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.76370436937...|[4.83504604584125...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.77750356542...|[1.29629003231060...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.52545150108...|[1.66788845399350...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.34730204043...|[7.33232739039779...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.29092041028...|[7.75761243843077...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.29092041028...|[7.75761243843077...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.15642623208...|[8.87438280274655...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.85825380066...|[1.19572910378445...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.61844951929...|[1.51977213036460...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.34946116290...|[1.98883445428260...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.34946116290...|[1.98883445428260...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-122.55511414083...|[5.95648701833356...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-121.49080078883...|[1.72669493630304...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-120.95282407604...|[2.9570313791545E...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.921473314905...|[6.54921576446130...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.880476563733...|[2.51014887223939...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-89.144670294284...|[1.92735449086230...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-89.144670294284...|[1.92735449086230...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.158469490335...|[5.16729394414514...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.704707542818...|[8.13447403457227...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.845825851484...|[2.59865180832977...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.975525403836...|[2.28254996320246...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.580853992793...|[3.38706794437072...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.486684554391...|[1.01161592631900...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.680697458741...|[3.06522558812808...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.303740467892...|[4.46861339872252...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.535442608662...|[9.63474675928757...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.774574878652...|[7.58553958055640...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.774574878652...|[7.58553958055640...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-86.788374074704...|[2.03370541970956...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.796305796551...|[7.42247700929131...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.661811618354...|[8.49100194780546...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.990915494318...|[6.10985555682405...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.712144439575...|[2.97033335480735...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-87.706178393539...|[8.12251823233189...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.104866302286...|[5.45183541013002...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-54.013734223145...|[3.48444232090563...|       1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|[-88.253330885414...|[4.69964860653157...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 50 rows\n",
      "\n",
      "AUC:  1.0\n",
      "Accuracy: 100.00 %\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Running Logistic Regression Model\n",
    "classifier = LogisticRegression()\n",
    "# fitting the model with training data\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "#Evaluation method for binary classification problem\n",
    "predictionAndLabels = fitModel.transform(test)\n",
    "predictionAndLabels.show(50)\n",
    "\n",
    "auc = Bin_evaluator.evaluate(predictionAndLabels)\n",
    "print(\"AUC: \",auc)\n",
    "\n",
    "# Evaluation for a multiclass classification problems\n",
    "accuracy = (MC_evaluator.evaluate(predictionAndLabels))*100\n",
    "print(\"Accuracy: {0:.2f}\".format(accuracy),\"%\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [123.77857371205951]\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.02735478, -0.02672313, -0.02633224, -0.02777293, -0.02653522,\n",
      "              -0.02699613, -0.02681948, -0.02591789, -0.0269732 , -0.02650024,\n",
      "              -0.00135316, -0.08128871,  0.00026419, -0.00134494, -0.00092982,\n",
      "              -0.00029817, -0.0017696 ]])\n"
     ]
    }
   ],
   "source": [
    "# printing coefficients and intercepts for the Logistic Regression Model\n",
    "print(\"Intercept: \" + str(fitModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(fitModel.coefficientMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             feature|               coeff|\n",
      "+--------------------+--------------------+\n",
      "|                  A1|-0.02735477980626631|\n",
      "|                  A2|-0.02672312961569...|\n",
      "|                  A3|-0.02633224231177893|\n",
      "|                  A4|-0.02777292594537...|\n",
      "|                  A5|-0.02653521991148...|\n",
      "|                  A6|-0.02699613317549738|\n",
      "|                  A7|-0.02681947765624...|\n",
      "|                  A8|-0.02591789414214...|\n",
      "|                  A9|-0.02697320473547904|\n",
      "|                 A10|-0.02650023763011...|\n",
      "|            Age_Mons|-0.00135315912357...|\n",
      "|      Qchat-10-Score|-0.08128871161811413|\n",
      "|             Sex_num|2.641937305502643...|\n",
      "|       Ethnicity_num|-0.00134494178197...|\n",
      "|        Jaundice_num|-9.29819173799127...|\n",
      "|Family_mem_with_A...|-2.98172431423883...|\n",
      "|Who completed the...|-0.00176959932155...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# representing the coefficients with the predictors\n",
    "# we will make a dataframe out of this to better see the coefficients along with the corresponding predictors\n",
    "# convert the coefficients score from array to a list\n",
    "coeff_array = fitModel.coefficientMatrix.toArray()\n",
    "coeff_score = [] # creating an empty list\n",
    "\n",
    "# checking each coefficients and appending them into a list\n",
    "for x in coeff_array[0]:\n",
    "    coeff_score.append(float(x))\n",
    "\n",
    "# Create a dataframe\n",
    "result = spark.createDataFrame(zip(features_list,coeff_score), schema=['feature', 'coeff'])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------------------+\n",
      "|feature                   |coeff                 |\n",
      "+--------------------------+----------------------+\n",
      "|A1                        |-0.02735477980626631  |\n",
      "|A2                        |-0.026723129615697533 |\n",
      "|A3                        |-0.02633224231177893  |\n",
      "|A4                        |-0.027772925945378862 |\n",
      "|A5                        |-0.026535219911480435 |\n",
      "|A6                        |-0.02699613317549738  |\n",
      "|A7                        |-0.026819477656247075 |\n",
      "|A8                        |-0.025917894142145046 |\n",
      "|A9                        |-0.02697320473547904  |\n",
      "|A10                       |-0.026500237630119588 |\n",
      "|Age_Mons                  |-0.0013531591235770545|\n",
      "|Qchat-10-Score            |-0.08128871161811413  |\n",
      "|Sex_num                   |2.6419373055026435E-4 |\n",
      "|Ethnicity_num             |-0.0013449417819735722|\n",
      "|Jaundice_num              |-9.298191737991273E-4 |\n",
      "|Family_mem_with_ASD_num   |-2.981724314238838E-4 |\n",
      "|Who completed the test_num|-0.0017695993215565778|\n",
      "+--------------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Accuracy of the model with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [34.330061127051316]\n",
      "Coefficients: \n",
      "DenseMatrix([[-7.98130008e-03, -7.82444281e-03, -6.89856891e-03,\n",
      "              -6.80761477e-03, -6.91467163e-03, -7.53457683e-03,\n",
      "              -7.58818825e-03, -7.47400471e-03, -7.22033755e-03,\n",
      "              -7.46764240e-03,  4.76900044e-04, -2.23545278e-02,\n",
      "              -1.30667153e-04, -1.11644272e-03,  1.09032197e-05,\n",
      "              -1.76942754e-04, -2.44335744e-03]])\n",
      "LogisticRegressionModel: uid = LogisticRegression_9d4be74c11ef, numClasses = 2, numFeatures = 17\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# first we need to the classifier we need to use\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Setting up the parameter grid for cross validator to conduct hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10, 15, 20]).build())\n",
    "paramGrid\n",
    "# Setting up the Cross Validator \n",
    "crossval = CrossValidator(estimator= classifier,\n",
    "                         estimatorParamMaps=paramGrid,\n",
    "                         evaluator = MC_evaluator,\n",
    "                         numFolds = 4)\n",
    "\n",
    "# fit the model\n",
    "fitModel1 = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel1.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "print(BestModel)\n",
    "\n",
    "# we don't need to use BestModel, fitModel1 automatically use best model, hence we can directly use\n",
    "# fitModel1 on the test data\n",
    "predictions = fitModel1.transform(test)\n",
    "\n",
    "# Checking accuracy of the model\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
